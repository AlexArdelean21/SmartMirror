# Smart Mirror Project Structure

This document provides a detailed breakdown of the file and directory structure of the Smart Mirror project.

## Root Directory

### `app.py`

This is the main application file, built using the Flask web framework. It serves as the central hub for the smart mirror's backend operations.

**Key Responsibilities:**

-   **Web Server:** It runs the Flask development server to handle HTTP requests.
-   **API Endpoints:** It defines various API routes (`@app.route`) to provide data to the frontend, such as:
    -   `/`: Renders the main user interface (`index.html`).
    -   `/time_date`, `/weather`, `/news`, `/crypto`: Fetches and returns data from their respective services. These endpoints use caching to improve performance.
    -   `/calendar`: Retrieves calendar events for the logged-in user.
    -   `/add_event`: Adds a new event to the user's calendar.
    -   `/add_face`, `/recognize_faces`: Manages facial recognition functionalities.
    -   `/find_clothing`: Searches for clothing items based on user preferences.
-   **WebSocket Communication:** It uses `Flask-SocketIO` to manage real-time communication with the frontend. The `audio_finished` event is used to track the state of audio playback on the client.
-   **Background Processes:** It starts a background thread to listen for the wake word ("Hey Adonis") and subsequent voice commands.
-   **Caching:** Implements a simple in-memory cache to reduce redundant API calls for data that doesn't change frequently.

### `hey_adonis.ppn`

This is a model file for the Porcupine wake word engine. It is trained to recognize the phrase "Hey Adonis" to activate the voice assistant. This file is proprietary to the Picovoice platform and contains the model data required for wake word detection.

### `cache.json`

This file is used for caching data, specifically for the product search functionality. It stores the results of previous searches to speed up responses and avoid redundant calls to external APIs.

### `logs/`

This directory contains log files generated by the application. The `logger.py` utility is configured to write logs to this directory, which is essential for debugging and monitoring the application's behavior. 

### `Overview of the Project.txt`

This file contains development notes, reminders, and a list of available voice commands. It appears to be a scratchpad for the developer.

**Key Information:**

-   **Configuration Notes:** Instructions on how to change the wake word, AI model, and text-to-speech voice in `voice_service.py`.
-   **Platform-Specific Notes:** A reminder that the `.ppn` wake word file is specific to Windows.
-   **API Keys:** A note about API credit limits for OpenAI.
-   **Calendar Logic:** An explanation that calendar events only appear if the service account's email is invited to the event.
-   **Voice Commands:** A list of supported voice commands for various services like event management, weather, news, crypto, facial recognition, and virtual try-on.
-   **Development To-Dos:** A list of future features and bug fixes.

### `pictures/`

This directory stores images related to the project.

-   **`known_faces.pkl`**: This is a pickled file that contains the encoded facial features of known users. The facial recognition service uses this file to identify individuals. It is generated and updated by the `facial_recognition_service.py`.

### `README.md`

This file serves as the primary documentation for the project. It provides a comprehensive overview of the smart mirror's features, technical implementation, setup instructions, and usage guidelines.

**Key Sections:**

-   **Enhanced Features:** Details the advanced capabilities of the virtual try-on system, including pose estimation, clothing-specific behaviors, and realistic rendering.
-   **Technical Implementation:** Describes the frontend and backend technologies used, such as MediaPipe, TensorFlow.js, Flask, and `rembg`.
-   **Installation & Setup:** Provides step-by-step instructions for setting up the backend and frontend environments.
-   **API Endpoints:** Lists the available API routes for the try-on system and real-time features.
-   **Usage Instructions:** Explains how to interact with the mirror using both voice commands and manual controls.
-   **Configuration & Customization:** Shows how to modify pose detection settings, add new clothing categories, and customize the styling.
-   **Troubleshooting & Performance:** Offers solutions for common issues and tips for optimizing performance.

### `requirements.txt`

This file lists the Python packages required for the project to run. These dependencies can be installed using `pip install -r requirements.txt`.

**Key Dependencies:**

-   **`flask`**: A lightweight web framework for the backend API.
-   **`python-dotenv`**: Manages environment variables.
-   **`SpeechRecognition`**: Library for performing speech recognition.
-   **`pvporcupine`**: The Porcupine wake word detection engine.
-   **`pyaudio`**: Provides Python bindings for PortAudio, the cross-platform audio I/O library. Used for microphone input.
-   **`google-cloud-texttospeech`**: Google Cloud's Text-to-Speech API client library.
-   **`openai`**: The official client library for the OpenAI API, used for natural language understanding and generation.
-   **`requests`**: A simple HTTP library for making API calls to external services.
-   **`rembg`**: A tool to remove the background from images.
-   **`pillow`**: A friendly fork of the Python Imaging Library (PIL), used for image manipulation.
-   **`numpy`**: A fundamental package for scientific computing with Python, often used with image and numerical data.

## Services

This directory contains modules that provide specific functionalities or "services" to the application. Each service is responsible for a distinct domain, such as weather, news, or facial recognition.

### `calendar_service.py`

This module handles interactions with the Google Calendar API to manage events.

**Key Functions:**

-   **`get_calendar_service()`**: Authenticates with the Google Calendar API using service account credentials and returns a service object.
-   **`get_upcoming_events(max_results=5)`**: Fetches the next 5 upcoming events from the specified calendar.
-   **`add_event(summary, start_time, end_time, description=None)`**: Adds a new event to the calendar.

### `crypto_service.py`

This module is responsible for fetching cryptocurrency prices from the CoinGecko API.

**Key Functions:**

-   **`get_crypto_prices()`**: Fetches the current prices for Bitcoin and Ethereum in USD. It uses a caching mechanism (`util/cache.py`) to avoid making excessive API calls.

### `datetime_service.py`

This is a simple utility module that provides the current time and date.

**Key Functions:**

-   **`get_time_date()`**: Returns the current time (HH:MM) and date (YYYY-MM-DD) as a dictionary. It also stores the data in the cache.

### `facial_recognition_service.py`

This module manages all facial recognition functionalities, including identifying users and registering new faces. It uses the `face_recognition` library.

**Key Functions:**

-   **`load_known_faces()`**: Loads the serialized database of known faces from `pictures/known_faces.pkl`.
-   **`save_known_faces(known_faces)`**: Saves the updated database of faces back to the pickle file.
-   **`recognize_faces_vocally()`**: Activates the camera to detect and recognize a face. It compares the detected face against the known faces and returns the name of the recognized person or "Unknown".
-   **`add_face_vocally(name=None)`**: Initiates the process of registering a new face. It captures a face from the camera, encodes it, and saves it with the provided name.
-   **`list_registered_faces()` / `delete_face_by_name(name)`**: Admin functions for managing the list of registered users.

### `news_service.py`

This module fetches news articles from the GNews API.

**Key Functions:**

-   **`get_news(topics=None)`**: Fetches the top 10 news articles for a given list of topics (defaults to "technology"). It uses a topic-specific cache to improve performance.

### `product_search_service.py`

This module manages the virtual try-on feature. It fetches clothing items from the Fake Store API, processes them, and handles the interaction logic for trying them on.

**Key Functions:**

-   **`get_clothing_items(category, color, max_price)`**: Fetches clothing items from the API based on the specified filters. It also removes the background from the product images using `util/image_utils.py`.
-   **`handle_tryon_command(command)`**: Parses a voice command to extract clothing category, color, and maximum price. It then fetches the matching items and sends them to the frontend via a WebSocket event (`trigger_tryon`).
-   **`handle_tryon_dismissal()`**: Hides the try-on user interface on the frontend.
-   **`handle_tryon_selection_command(command)`**: Parses a voice command to select a specific item to try on and sends the selection to the frontend via a WebSocket event (`try_on_selected_item`).

### `recommendation_service.py`

This module uses the OpenAI GPT model to generate personalized recommendations for the user.

**Key Functions:**

-   **`generate_personal_recommendation(user_profile)`**: Generates a recommendation based on the user's location, the current weather, upcoming calendar events, and the time of day. It constructs a prompt with this information and sends it to the OpenAI API.

### `user_profile_service.py`

This module manages user profiles, which are stored as JSON files in the `user_profiles/` directory.

**Key Functions:**

-   **`get_user_profile(username)`**: Loads a user's profile from their corresponding JSON file.
-   **`save_user_profile(username, profile_data)`**: Saves a user's profile data to a JSON file.
-   **`create_default_profile(username)`**: Creates a new profile with default settings.
-   **`create_profile_interactively(username)`**: Guides a new user through an interactive voice-based setup to create their profile, asking for information like their location and preferred news topics.

### `voice_service.py`

This is the most complex and central module in the application. It orchestrates the entire voice-based interaction, from wake word detection to command processing and response generation.

**Key Components & Responsibilities:**

-   **Wake Word Detection:**
    -   `wake_word_detected()`: Uses the `pvporcupine` library to listen for the "Hey Adonis" wake word in the background.

-   **Command Interruption:**
    -   A background thread (`listen_for_stop_command_thread`) is implemented to listen for a "stop" command. This allows the user to interrupt long-running actions, such as a lengthy audio response.

-   **Command Processing:**
    -   `process_command(command, user_profile)`: This is the main router for voice commands. It takes the transcribed command and determines which service should handle it based on keywords. It supports a wide range of commands:
        -   **Calendar:** "add an event", "do I have any plans"
        -   **Time/Date:** "time", "date"
        -   **Weather:** "weather"
        -   **News:** "news"
        -   **Crypto:** "crypto"
        -   **Facial Recognition:** "start facial recognition", "add my face"
        -   **Virtual Try-On:** Manages try-on, selection, and dismissal commands.
        -   **Recommendations:** "recommend", "suggest", "what should I wear"

-   **Main Interaction Loop:**
    -   `wait_for_wake_and_command()`: This function runs in a continuous loop in a background thread (started from `app.py`). It performs the following steps:
        1.  Waits for the wake word to be detected.
        2.  Performs facial recognition to identify the user and load their profile. If the user is unknown, it initiates the profile creation process.
        3.  Listens for a voice command using `listen_command()`.
        4.  Processes the command using `process_command()`.
        5.  If the command is not recognized, it falls back to `chat_with_gpt()` for a conversational response.
        6.  Speaks the response back to the user using `speak_response()`.
        7.  Asks for a follow-up command to maintain the conversation.

-   **AI Integration:**
    -   `chat_with_gpt(prompt)`: Sends the user's query to the OpenAI GPT model to handle general questions and conversations that don't match any specific command.

-   **Utility Functions:**
    -   `handle_command(command)`: Uses regex to parse details from commands, such as event summaries and times.
    -   `random_phrase(phrases)`: Selects a random phrase from a list to make interactions feel more natural. 

### `weather_service.py`

This module is responsible for fetching current weather data from the OpenWeatherMap API.

**Key Functions:**

-   **`get_weather(location=None)`**: Fetches the current weather for a given location (defaults to the location set in the environment variables). It returns the temperature in Celsius, a weather description, and an icon URL. It uses location-specific caching to reduce API calls. 

## Frontend - `static/`

This directory contains all the static assets for the frontend of the application. These files are served directly to the client's web browser.

### `processed_products/`

This directory is used to cache the background-removed images of clothing items for the virtual try-on feature. When a product image is processed for the first time, the result is saved here to speed up future requests.

### `audio_response.mp3`

This is a temporary audio file generated by the text-to-speech engine (`voice_utils.py`). When the voice assistant needs to speak, it generates this MP3 file, which is then played by the frontend.

### `script.js`

This is the main JavaScript file that powers the entire frontend user interface and handles all client-side logic.

**Key Responsibilities:**

-   **Data Fetching:**
    -   Periodically fetches data from the backend API endpoints (`/time_date`, `/weather`, `/news`, `/crypto`, `/calendar`) to keep the widgets on the screen updated.
    -   It includes a mechanism to only update the DOM if the fetched data has actually changed, improving performance.

-   **WebSocket Communication:**
    -   Establishes and manages a `Socket.IO` connection with the backend.
    -   Listens for various events from the server:
        -   `play_audio`: Receives an audio file URL and text to display, adding them to a queue to be played sequentially.
        -   `stop_audio`: Immediately stops any currently playing audio and clears the queue.
        -   `start_listening` / `stop_listening`: Updates the UI to show that the assistant is listening for a command.
        -   `trigger_tryon`: Initiates the virtual try-on experience by displaying clothing options.
        -   `try_on_selected_item`: Receives the index of a selected item and displays it on the user.
        -   `hide_tryon`: Hides the try-on interface.
    -   Emits `audio_finished` event to the server when an audio response has finished playing.

-   **Audio Management:**
    -   `processAudioQueue()`: Manages a queue of audio responses to ensure they are played one after another without overlapping.

-   **Virtual Try-On:**
    -   `LiveTryOn` Class: A comprehensive class that encapsulates the logic for the real-time virtual try-on feature.
    -   **Pose Estimation:** Uses the MediaPipe Pose library to detect the user's body landmarks from the webcam feed.
    -   **Clothing Overlay:** Renders the selected clothing item over the user's body, dynamically adjusting its size and position based on the detected pose. It includes logic for different clothing types (e.g., jackets, shirts, pants).
    -   **UI Management:** Controls the visibility of different UI elements during the try-on process.

-   **DOM Manipulation:**
    -   Updates the content of all the widget elements.
    -   Adds subtle animations (`widget-update` class) when content changes to provide visual feedback.
    -   Dynamically creates and manages the UI for clothing selection.
    -   Controls the theme of the page (e.g., day/night mode).

### `style.css`

This file contains all the CSS rules to style the frontend of the smart mirror.

**Key Features:**

-   **Layout:**
    -   Uses a CSS Grid to arrange the widgets in a two-column layout on larger screens, which collapses to a single column on smaller screens (responsive design).

-   **Visual Effects:**
    -   **Frosted Glass:** Applies a `backdrop-filter: blur()` to the widgets to create a modern "frosted glass" effect, making them semi-transparent.
    -   **Dynamic Background:** Implements a dynamic background gradient that transitions smoothly based on the time of day (controlled by `.theme-morning`, `.theme-afternoon`, etc. classes added via JavaScript).

-   **Animations:**
    -   **Widget Updates:** Defines keyframe animations (`fadeInUp`, `scaleUp`) to provide visual feedback when widget content is updated.
    -   **Listening Indicator:** Includes animations (`listeningPulse`, `micGlow`) to make the microphone icon and voice response box pulse when the assistant is listening.

-   **Styling:**
    -   Provides styling for all the individual widgets, text, icons, and the components of the virtual try-on feature.

## HTML Templates - `templates/`

This directory contains the HTML files that are rendered by Flask. These files define the structure of the web pages.

### `index.html`

This is the main HTML file for the smart mirror application. It defines the structure of the user interface.

**Key Elements:**

-   **Scripts and Stylesheets:** It links to the `style.css` file, the Font Awesome icon library, and all the necessary JavaScript libraries, including `socket.io`, MediaPipe, and the application's own `script.js`.
-   **Widget Containers:** It defines the `div` elements that act as containers for all the informational widgets (Time/Date, Weather, News, Crypto, Calendar). Each widget has a unique ID that is used by `script.js` to populate it with data.
-   **Virtual Try-On Containers:** It includes containers for the virtual try-on feature (`tryon-options` and `tryon-preview`), which are hidden by default and shown by `script.js` when the feature is activated. This section also contains the `video` and `canvas` elements required for MediaPipe.
-   **Voice Response:** It contains the UI elements for displaying the voice assistant's status, including the microphone icon and the text response.

### `test_themes.html`

This is a developer utility page used for testing the visual themes of the application.

**Key Features:**

-   **Theme Switcher:** It provides buttons to manually switch between the "Morning", "Afternoon", "Evening", and "Night" themes.
-   **Includes Main UI:** It includes the `index.html` template, so the theme changes can be previewed on the actual user interface.
-   **Transition Test:** A "Test Transition" button cycles through all the themes automatically, allowing developers to check the smoothness of the background gradient transitions.

## Utilities - `util/`

This directory contains various utility modules that provide helper functions and shared functionality used across the application.

### `audio_state.py`

This module manages the global state of audio playback. It helps the application know whether an audio response is currently playing on the frontend. This is used by the `voice_service` to avoid listening for new commands while the assistant is speaking.

**Key Functions:**

-   **`set_audio_playing(value: bool)`**: Sets the audio playback state (True or False).
-   **`is_audio_playing()`**: Returns the current audio playback state.

### `cache.py`

This module provides a simple file-based caching system to store temporary data and reduce redundant API calls. The cache is stored in a JSON file (`cache.json` by default).

**Key Functions:**

-   **`load_cache()` / `save_cache(cache)`**: Functions to load the cache from and save it to the JSON file.
-   **`get_cached_data(key)`**: Retrieves data from the cache for a given key, but only if the data has not expired (default timeout is 5 minutes).
-   **`set_cache(key, data)`**: Stores data in the cache with the current timestamp.

### `command_interrupt.py`

This module provides a thread-safe mechanism to globally signal that a "stop" command has been issued by the user. This is crucial for interrupting long-running tasks in the `voice_service`.

**Key Functions:**

-   **`set_stop_requested(value: bool)`**: Sets the global stop flag.
-   **`is_stop_requested()`**: Checks the value of the stop flag.
-   **`reset_stop_requested()`**: Resets the stop flag to `False` after the stop command has been handled. 

### `image_utils.py`

This module provides utilities for image processing, specifically for removing the background from product images for the virtual try-on feature.

**Key Functions:**

-   **`remove_background(image_url: str)`**:
    -   Downloads an image from a given URL.
    -   Uses the `rembg` library to remove the background.
    -   Saves the processed image with a transparent background as a PNG file in the `static/processed_products/` directory.
    -   Implements a caching mechanism: if an image has already been processed, it returns the path to the cached file instead of processing it again.

### `logger.py`

This module configures a comprehensive logging system for the entire application using Python's built-in `logging` library.

**Key Features:**

-   **Multiple Handlers:** It sets up multiple logging handlers:
    -   A `RotatingFileHandler` to write all logs (from DEBUG level upwards) to `logs/smart_mirror.log`.
    -   Another `RotatingFileHandler` to write only ERROR level logs to `logs/error.log`.
    -   A `StreamHandler` to print logs to the console.
-   **Log Rotation:** The file handlers are configured to rotate log files when they reach a certain size, preventing them from growing indefinitely.
-   **Colorized Console Output:** It uses a custom `ColorFormatter` to add colors to the console logs based on the log level (e.g., yellow for warnings, red for errors), which improves readability.
-   **Centralized Logger:** It creates a single, centralized logger instance named "SmartMirror" that is imported and used by all other modules in the application.

### `session_state.py`

This module provides a simple in-memory store for session-specific data. It is used to keep track of the currently active user profile and other temporary attributes related to the current interaction.

**Key Functions:**

-   **`set_active_profile(profile)` / `get_active_profile()`**: Getters and setters for the currently logged-in user's profile.
-   **`set_session_attribute(key, value)`**: Stores a key-value pair in the session. This is used, for example, to track if the virtual try-on feature is currently active (`tryon_active`).
-   **`get_session_attribute(key)`**: Retrieves a value from the session.
-   **`clear_session_attribute(key)`**: Removes a key from the session.

### `socket_manager.py`

This module is responsible for creating and managing the global `SocketIO` instance from the `Flask-SocketIO` library.

**Key Features:**

-   **Centralized Instance:** It initializes a single `socketio` object that is then imported by `app.py` to set up the WebSocket server and by other modules (like `product_search_service.py`) to emit events to the frontend. This avoids circular import issues.
-   **Initial State:** It also ensures that the audio playing state is initialized to `False` when the application starts.

### `voice_utils.py`

This module contains essential utilities for handling the two core components of voice interaction: converting text to speech (TTS) and transcribing speech to text (STT).

**Key Functions:**

-   **`speak_response(text)`**:
    -   Takes a string of text as input.
    -   Uses the Google Cloud Text-to-Speech API to convert the text into an MP3 audio file.
    -   Saves the audio as `static/audio_response.mp3`.
    -   Emits a `play_audio` event via WebSocket to the frontend, telling it to play the newly generated audio file.
    -   Calls `wait_for_audio_completion()` to pause execution until the frontend signals that the audio has finished playing.

-   **`listen_command()`**:
    -   Uses the `SpeechRecognition` library to listen for a command from the user via the microphone.
    -   Emits `start_listening` and `stop_listening` events to the frontend to update the UI.
    -   Uses Google's speech recognition service to transcribe the audio into text.
    -   Returns the transcribed text in lowercase.

-   **`wait_for_audio_completion(timeout=60)`**:
    -   A crucial function for synchronizing the backend and frontend. It polls the global audio state (managed by `audio_state.py`) and waits until it is set to `False`.
    -   The state is set to `False` when the frontend's JavaScript emits an `audio_finished` event back to the server upon completion of the audio playback.
    -   This prevents the voice assistant from trying to listen for a new command while it is still speaking. It includes a timeout to prevent it from getting stuck. 

## User Data - `user_profiles/`

This directory stores the profiles of registered users as individual JSON files. Each file is named after the user (e.g., `alex.json`) and contains their personalized settings, such as location and news preferences. This information is managed by the `user_profile_service.py`. 